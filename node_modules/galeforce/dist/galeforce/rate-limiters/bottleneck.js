"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const bottleneck_1 = __importDefault(require("bottleneck"));
const lodash_1 = __importDefault(require("lodash"));
const debug_1 = __importDefault(require("debug"));
const chalk_1 = __importDefault(require("chalk"));
const Redis = __importStar(require("redis"));
const rate_limiter_1 = __importDefault(require("./rate-limiter"));
const ratelimitDebug = (0, debug_1.default)('galeforce:rate-limit');
class BottleneckRateLimiter extends rate_limiter_1.default {
    constructor(config) {
        super(config);
        let options;
        if (config.cache.type === 'redis' && typeof config.cache.uri !== 'undefined') {
            options = {
                /* Limiter options */
                maxConcurrent: config.options['max-concurrent'],
                minTime: config.options['min-time'],
                /* Clustering options */
                id: config.cache['key-id'],
                datastore: 'redis',
                clientOptions: {
                    url: config.cache.uri,
                },
                // timeout should default to 300 seconds
                timeout: (lodash_1.default.max(Object.keys(config.options.intervals).map((time) => parseInt(time, 10))) || 300) * 1000,
                // Explicitly pass in Redis object to prevent conflict with node-redis@4.x
                Redis,
            };
        }
        else if (config.cache.type === 'internal') {
            options = {
                /* Limiter options */
                maxConcurrent: config.options['max-concurrent'],
                minTime: config.options['min-time'],
                /* Clustering options */
                // timeout should default to 300 seconds
                timeout: (lodash_1.default.max(Object.keys(config.options.intervals).map((time) => parseInt(time, 10))) || 300) * 1000,
            };
        }
        else {
            throw new Error('[galeforce]: Invalid rate limit cache type provided in config.');
        }
        ratelimitDebug(`${chalk_1.default.bold.blueBright('create')} ${chalk_1.default.bold.red('bottleneck')} \u00AB %O`, options);
        this.group = new bottleneck_1.default.Group(options);
        // Set options when creating new rate limiters
        this.group.on('created', (limiter, key) => {
            ratelimitDebug(`${chalk_1.default.bold.red(key)} | ${chalk_1.default.bold.blueBright('create')} \u00AB ${chalk_1.default.bold.red('limiter')}`);
            Object.entries(config.options.intervals).forEach(([interval, limit]) => {
                limiter.chain(new bottleneck_1.default({
                    reservoir: limit,
                    reservoirRefreshInterval: parseInt(interval, 10) * 1000,
                    reservoirRefreshAmount: limit,
                }));
            });
            // Handle failed requests and queue retry attempts
            limiter.on('failed', async (error, jobInfo) => {
                ratelimitDebug(`${chalk_1.default.bold.red(key)} | ${chalk_1.default.bold.redBright('failed')}`);
                // Retry if (1) an HTTP 429 error is returned, (2) a retry-after header is provided, and (3) the number of retry attempts is less than the configured maximum
                if (error.response.status === 429 && error.response.headers['retry-after'] && jobInfo.retryCount < config.options['retry-count-after-429']) {
                    const waitTime = parseInt(error.response.headers['retry-after'], 10) * 1000;
                    ratelimitDebug(`${chalk_1.default.bold.red(key)} | ${chalk_1.default.bold.magenta('retry')} (${chalk_1.default.bold.cyan(jobInfo.retryCount + 1)}/${chalk_1.default.bold.blue(config.options['retry-count-after-429'])}) in ${chalk_1.default.bold.magenta(waitTime)} ms`);
                    return waitTime; // Retry the original request after the amount of time specified by the response headers
                }
            });
        });
    }
    schedule(request, region) {
        if (region) {
            ratelimitDebug(`${chalk_1.default.bold.red(region)} | ${chalk_1.default.bold.yellow('schedule')}`);
            return this.group.key(region).schedule(request); // Schedule request through limiter only if region is specified
        }
        return request();
    }
}
exports.default = BottleneckRateLimiter;
//# sourceMappingURL=bottleneck.js.map